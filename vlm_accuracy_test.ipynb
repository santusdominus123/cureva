{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§ª VLM Accuracy Testing - Google Colab\n",
    "\n",
    "Notebook untuk testing akurasi model VLM (Vision Language Model) dengan berbagai jenis gambar.\n",
    "\n",
    "**Model yang ditest:**\n",
    "- Google Gemini 2.0 Flash\n",
    "- OpenAI GPT-4o (optional)\n",
    "\n",
    "**Jenis Testing:**\n",
    "1. Objek Bersejarah (Artifact)\n",
    "2. Bangunan/Arsitektur\n",
    "3. Alam/Lingkungan\n",
    "4. Analisis Umum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install google-generativeai pillow requests pandas matplotlib seaborn scikit-learn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”‘ Setup API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "# Setup API Key\n",
    "# Option 1: Dari Colab Secrets (Recommended)\n",
    "try:\n",
    "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "except:\n",
    "    # Option 2: Input manual\n",
    "    from getpass import getpass\n",
    "    GEMINI_API_KEY = getpass('Enter your Gemini API Key: ')\n",
    "\n",
    "# Configure Gemini\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "print(\"âœ… API Key configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Upload Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# Upload gambar untuk testing\n",
    "print(\"Upload gambar untuk testing (bisa multiple files):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Simpan gambar\n",
    "test_images = []\n",
    "for filename, data in uploaded.items():\n",
    "    image = Image.open(io.BytesIO(data))\n",
    "    test_images.append({\n",
    "        'filename': filename,\n",
    "        'image': image,\n",
    "        'data': data\n",
    "    })\n",
    "    print(f\"âœ… Loaded: {filename} ({image.size})\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Total gambar: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ VLM Service Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import time\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "class VLMTester:\n",
    "    def __init__(self, api_key: str):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
    "    \n",
    "    def analyze_image(self, image_data: bytes, prompt: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analisis gambar dengan prompt custom\"\"\"\n",
    "        try:\n",
    "            # Prepare image\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "            \n",
    "            # Generate content\n",
    "            start_time = time.time()\n",
    "            response = self.model.generate_content([prompt, image])\n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # Parse response\n",
    "            text = response.text\n",
    "            \n",
    "            # Try to extract JSON\n",
    "            result = None\n",
    "            try:\n",
    "                json_match = text[text.find('{'):text.rfind('}')+1]\n",
    "                result = json.loads(json_match)\n",
    "            except:\n",
    "                result = {'description': text}\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'result': result,\n",
    "                'raw_text': text,\n",
    "                'processing_time': processing_time\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': str(e),\n",
    "                'processing_time': 0\n",
    "            }\n",
    "    \n",
    "    def test_artifact_analysis(self, image_data: bytes) -> Dict[str, Any]:\n",
    "        \"\"\"Test analisis objek bersejarah\"\"\"\n",
    "        prompt = \"\"\"Analisis gambar objek bersejarah ini dalam Bahasa Indonesia.\n",
    "        \n",
    "        Berikan informasi detail:\n",
    "        1. Identifikasi jenis objek\n",
    "        2. Estimasi periode/era\n",
    "        3. Kondisi objek\n",
    "        4. Tingkat kerusakan (none/low/medium/high/severe)\n",
    "        5. Nilai historis\n",
    "        6. Rekomendasi preservasi\n",
    "        \n",
    "        Format JSON:\n",
    "        {\n",
    "            \"object_type\": \"jenis objek\",\n",
    "            \"period\": \"periode/era\",\n",
    "            \"condition\": \"kondisi\",\n",
    "            \"damage_level\": \"none/low/medium/high/severe\",\n",
    "            \"historical_value\": \"nilai historis\",\n",
    "            \"recommendations\": [\"rekomendasi1\", \"rekomendasi2\"],\n",
    "            \"confidence\": \"0-100%\"\n",
    "        }\"\"\"\n",
    "        return self.analyze_image(image_data, prompt)\n",
    "    \n",
    "    def test_building_analysis(self, image_data: bytes) -> Dict[str, Any]:\n",
    "        \"\"\"Test analisis bangunan\"\"\"\n",
    "        prompt = \"\"\"Analisis bangunan dalam gambar ini (Bahasa Indonesia).\n",
    "        \n",
    "        Berikan:\n",
    "        1. Jenis bangunan\n",
    "        2. Gaya arsitektur\n",
    "        3. Kondisi struktur\n",
    "        4. Deteksi kerusakan (retak, roboh, dll)\n",
    "        5. Tingkat kerusakan (none/low/medium/high/severe)\n",
    "        6. Prioritas perbaikan\n",
    "        \n",
    "        Format JSON:\n",
    "        {\n",
    "            \"building_type\": \"jenis\",\n",
    "            \"architecture_style\": \"gaya\",\n",
    "            \"structural_condition\": \"kondisi\",\n",
    "            \"detected_damages\": [\"kerusakan1\", \"kerusakan2\"],\n",
    "            \"damage_level\": \"none/low/medium/high/severe\",\n",
    "            \"repair_priority\": [\"prioritas1\", \"prioritas2\"],\n",
    "            \"confidence\": \"0-100%\"\n",
    "        }\"\"\"\n",
    "        return self.analyze_image(image_data, prompt)\n",
    "    \n",
    "    def test_nature_analysis(self, image_data: bytes) -> Dict[str, Any]:\n",
    "        \"\"\"Test analisis alam/lingkungan\"\"\"\n",
    "        prompt = \"\"\"Analisis foto alam/lingkungan ini (Bahasa Indonesia).\n",
    "        \n",
    "        Berikan:\n",
    "        1. Jenis ekosistem/area\n",
    "        2. Kondisi lingkungan\n",
    "        3. Kesehatan vegetasi\n",
    "        4. Potensi masalah (erosi, deforestasi, dll)\n",
    "        5. Tingkat kerusakan (none/low/medium/high/severe)\n",
    "        6. Rekomendasi konservasi\n",
    "        \n",
    "        Format JSON:\n",
    "        {\n",
    "            \"ecosystem_type\": \"jenis\",\n",
    "            \"environmental_condition\": \"kondisi\",\n",
    "            \"vegetation_health\": \"kesehatan\",\n",
    "            \"potential_issues\": [\"masalah1\", \"masalah2\"],\n",
    "            \"damage_level\": \"none/low/medium/high/severe\",\n",
    "            \"conservation_recommendations\": [\"rekomendasi1\"],\n",
    "            \"confidence\": \"0-100%\"\n",
    "        }\"\"\"\n",
    "        return self.analyze_image(image_data, prompt)\n",
    "    \n",
    "    def test_general_analysis(self, image_data: bytes) -> Dict[str, Any]:\n",
    "        \"\"\"Test analisis umum\"\"\"\n",
    "        prompt = \"\"\"Analisis gambar ini secara detail (Bahasa Indonesia).\n",
    "        \n",
    "        Berikan:\n",
    "        1. Deskripsi singkat\n",
    "        2. Objek-objek utama\n",
    "        3. Aktivitas/kejadian\n",
    "        4. Kondisi keseluruhan\n",
    "        5. Tag/kategori\n",
    "        \n",
    "        Format JSON:\n",
    "        {\n",
    "            \"description\": \"deskripsi\",\n",
    "            \"main_objects\": [\"objek1\", \"objek2\"],\n",
    "            \"activities\": [\"aktivitas1\"],\n",
    "            \"overall_condition\": \"kondisi\",\n",
    "            \"tags\": [\"tag1\", \"tag2\"],\n",
    "            \"confidence\": \"0-100%\"\n",
    "        }\"\"\"\n",
    "        return self.analyze_image(image_data, prompt)\n",
    "\n",
    "# Initialize tester\n",
    "tester = VLMTester(GEMINI_API_KEY)\n",
    "print(\"âœ… VLM Tester initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§ª Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pilih jenis test\n",
    "print(\"Pilih jenis analisis:\")\n",
    "print(\"1. Objek Bersejarah (Artifact)\")\n",
    "print(\"2. Bangunan/Arsitektur\")\n",
    "print(\"3. Alam/Lingkungan\")\n",
    "print(\"4. Analisis Umum\")\n",
    "print(\"5. Test Semua Jenis\")\n",
    "\n",
    "test_type = input(\"Pilih (1-5): \").strip()\n",
    "\n",
    "results = []\n",
    "\n",
    "for img_data in test_images:\n",
    "    filename = img_data['filename']\n",
    "    data = img_data['data']\n",
    "    \n",
    "    print(f\"\\nðŸ” Testing: {filename}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if test_type == '1' or test_type == '5':\n",
    "        print(\"\\nðŸ“œ Artifact Analysis...\")\n",
    "        result = tester.test_artifact_analysis(data)\n",
    "        results.append({\n",
    "            'filename': filename,\n",
    "            'test_type': 'artifact',\n",
    "            **result\n",
    "        })\n",
    "        print(f\"â±ï¸ Time: {result.get('processing_time', 0):.2f}s\")\n",
    "        if result['success']:\n",
    "            print(f\"ðŸ“Š Result: {json.dumps(result['result'], indent=2, ensure_ascii=False)}\")\n",
    "    \n",
    "    if test_type == '2' or test_type == '5':\n",
    "        print(\"\\nðŸ›ï¸ Building Analysis...\")\n",
    "        result = tester.test_building_analysis(data)\n",
    "        results.append({\n",
    "            'filename': filename,\n",
    "            'test_type': 'building',\n",
    "            **result\n",
    "        })\n",
    "        print(f\"â±ï¸ Time: {result.get('processing_time', 0):.2f}s\")\n",
    "        if result['success']:\n",
    "            print(f\"ðŸ“Š Result: {json.dumps(result['result'], indent=2, ensure_ascii=False)}\")\n",
    "    \n",
    "    if test_type == '3' or test_type == '5':\n",
    "        print(\"\\nðŸŒ¿ Nature Analysis...\")\n",
    "        result = tester.test_nature_analysis(data)\n",
    "        results.append({\n",
    "            'filename': filename,\n",
    "            'test_type': 'nature',\n",
    "            **result\n",
    "        })\n",
    "        print(f\"â±ï¸ Time: {result.get('processing_time', 0):.2f}s\")\n",
    "        if result['success']:\n",
    "            print(f\"ðŸ“Š Result: {json.dumps(result['result'], indent=2, ensure_ascii=False)}\")\n",
    "    \n",
    "    if test_type == '4' or test_type == '5':\n",
    "        print(\"\\nðŸ” General Analysis...\")\n",
    "        result = tester.test_general_analysis(data)\n",
    "        results.append({\n",
    "            'filename': filename,\n",
    "            'test_type': 'general',\n",
    "            **result\n",
    "        })\n",
    "        print(f\"â±ï¸ Time: {result.get('processing_time', 0):.2f}s\")\n",
    "        if result['success']:\n",
    "            print(f\"ðŸ“Š Result: {json.dumps(result['result'], indent=2, ensure_ascii=False)}\")\n",
    "\n",
    "print(\"\\nâœ… All tests completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "print(\"ðŸ“Š Test Results Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total tests: {len(results)}\")\n",
    "print(f\"Successful: {df_results['success'].sum()}\")\n",
    "print(f\"Failed: {(~df_results['success']).sum()}\")\n",
    "print(f\"\\nAverage processing time: {df_results['processing_time'].mean():.2f}s\")\n",
    "print(f\"Min time: {df_results['processing_time'].min():.2f}s\")\n",
    "print(f\"Max time: {df_results['processing_time'].max():.2f}s\")\n",
    "\n",
    "# Visualize processing times\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(data=df_results, x='test_type', y='processing_time')\n",
    "plt.title('Processing Time by Test Type')\n",
    "plt.xlabel('Test Type')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "success_counts = df_results['success'].value_counts()\n",
    "plt.pie(success_counts, labels=['Success', 'Failed'], autopct='%1.1f%%', colors=['#4CAF50', '#F44336'])\n",
    "plt.title('Success Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display detailed results\n",
    "print(\"\\nðŸ“‹ Detailed Results:\")\n",
    "display(df_results[['filename', 'test_type', 'success', 'processing_time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Accuracy Evaluation (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual accuracy evaluation\n",
    "# Buat ground truth dan compare dengan hasil VLM\n",
    "\n",
    "print(\"Manual Accuracy Evaluation\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nUntuk setiap hasil, beri rating akurasi (1-5):\")\n",
    "print(\"1 = Sangat tidak akurat\")\n",
    "print(\"2 = Tidak akurat\")\n",
    "print(\"3 = Cukup akurat\")\n",
    "print(\"4 = Akurat\")\n",
    "print(\"5 = Sangat akurat\\n\")\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    if result['success']:\n",
    "        print(f\"\\n{idx+1}. File: {result['filename']}\")\n",
    "        print(f\"   Type: {result['test_type']}\")\n",
    "        print(f\"   Result: {result.get('raw_text', '')[:200]}...\")\n",
    "        \n",
    "        score = int(input(\"   Rating (1-5): \"))\n",
    "        accuracy_scores.append({\n",
    "            'filename': result['filename'],\n",
    "            'test_type': result['test_type'],\n",
    "            'accuracy_score': score\n",
    "        })\n",
    "\n",
    "# Calculate metrics\n",
    "df_accuracy = pd.DataFrame(accuracy_scores)\n",
    "print(\"\\nðŸ“Š Accuracy Metrics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Average accuracy: {df_accuracy['accuracy_score'].mean():.2f}/5\")\n",
    "print(f\"Accuracy by type:\")\n",
    "print(df_accuracy.groupby('test_type')['accuracy_score'].mean())\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=df_accuracy, x='test_type', y='accuracy_score')\n",
    "plt.title('Average Accuracy Score by Test Type')\n",
    "plt.xlabel('Test Type')\n",
    "plt.ylabel('Accuracy Score (1-5)')\n",
    "plt.ylim(0, 5)\n",
    "plt.axhline(y=3, color='r', linestyle='--', label='Acceptable threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export ke CSV\n",
    "df_results.to_csv('vlm_test_results.csv', index=False)\n",
    "print(\"âœ… Results exported to: vlm_test_results.csv\")\n",
    "\n",
    "# Download file\n",
    "files.download('vlm_test_results.csv')\n",
    "\n",
    "# Export accuracy scores jika ada\n",
    "if len(accuracy_scores) > 0:\n",
    "    df_accuracy.to_csv('vlm_accuracy_scores.csv', index=False)\n",
    "    print(\"âœ… Accuracy scores exported to: vlm_accuracy_scores.csv\")\n",
    "    files.download('vlm_accuracy_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "report = f\"\"\"\n",
    "# VLM Accuracy Test Report\n",
    "\n",
    "## Test Configuration\n",
    "- Model: Google Gemini 2.0 Flash\n",
    "- Total Images: {len(test_images)}\n",
    "- Total Tests: {len(results)}\n",
    "\n",
    "## Performance Metrics\n",
    "- Success Rate: {df_results['success'].mean()*100:.1f}%\n",
    "- Average Processing Time: {df_results['processing_time'].mean():.2f}s\n",
    "- Min Processing Time: {df_results['processing_time'].min():.2f}s\n",
    "- Max Processing Time: {df_results['processing_time'].max():.2f}s\n",
    "\n",
    "## Accuracy Metrics\n",
    "\"\"\"\n",
    "\n",
    "if len(accuracy_scores) > 0:\n",
    "    report += f\"\"\"\n",
    "- Average Accuracy Score: {df_accuracy['accuracy_score'].mean():.2f}/5\n",
    "- Accuracy by Type:\n",
    "\"\"\"\n",
    "    for test_type, score in df_accuracy.groupby('test_type')['accuracy_score'].mean().items():\n",
    "        report += f\"  - {test_type}: {score:.2f}/5\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "## Test Types Distribution\n",
    "{df_results['test_type'].value_counts().to_string()}\n",
    "\n",
    "## Recommendations\n",
    "- Model shows good performance for VLM tasks\n",
    "- Average processing time is acceptable for production use\n",
    "- Consider fine-tuning for specific use cases if accuracy < 4/5\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "with open('vlm_test_report.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"\\nâœ… Report saved to: vlm_test_report.md\")\n",
    "files.download('vlm_test_report.md')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
